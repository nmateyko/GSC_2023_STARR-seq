import pathlib

pathlib.Path('job_logs/').mkdir(exist_ok=True)

configfile: "pipeline_config.yaml"

def get_input_fastqs(wildcards):
    sample_prefix = config["samples"][wildcards.sample]
    data_dir = "/arc/project/st-cdeboer-1/Sahu_data/raw_reads_Najmeh_Nick"
    return (f"{data_dir}/{sample_prefix}_1.fastq.gz", f"{data_dir}/{sample_prefix}_2.fastq.gz")


rule all:
    input:
        expand("output/counts/{sample}_counts.txt", sample=config["samples"])


rule ngmerge:
  input:
    get_input_fastqs
  output: 
    temp("output/paired/{sample}.fastq")
  log:
    "output/logs/NGmerge_failed_{sample}"
  conda:
    "environment.yaml"
  threads: 4
  resources:
    mem_mb=19200,
    walltime="01:00:00"
  shell:
    "NGmerge -1 {input[0]} -2 {input[1]} -o {output} -y -f {log} -n {threads}"
        

rule cluster:
    input:
        "output/paired/{sample}.fastq"
    output:
        temp("output/clustered/{sample}_clustered.txt")
    log:
        "output/logs/starcode/{sample}_starcode.log"
    conda:
        "environment.yaml"
    params:
        length=30,
        distance=3
    threads: 8
    resources:
        mem_mb=38400,
        walltime="01:00:00"
    shell:
        "cut -c-{params.length} {input} | starcode -o {output} -t {threads} -d {params.distance} --seq-id -c 2> {log}"


rule count:
    input:
        fq="output/paired/{sample}.fastq",
        clustered="output/clustered/{sample}_clustered.txt",
        script="../pipeline/scripts/get_cluster_counts.py"
    output:
        "output/counts/{sample}_counts.txt"
    log:
        "output/logs/count/{sample}.log"
    conda:
        "environment.yaml"
    params:
        distance=20
    threads: 8
    resources:
        mem_mb=38400,
        walltime="01:00:00"
    shell:
        "python {input.script} -f {input.fq} -c {input.clustered} -o {output} -l {log} -d {params.distance} -t {threads}"